{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *"]},{"cell_type":"markdown","metadata":{},"source":["স্পার্ক সেশন স্টার্ট করা হচ্ছেঃ"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["spark = SparkSession \\\n","    .builder \\\n","    .appName(\"readfromcsv\") \\\n","    .master(\"local[4]\")\\\n","    .getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["স্কিমা তৈরি করাঃ"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["schema1 = StructType([StructField('id', IntegerType(), True),\n","                      StructField('name', StringType(), True),\n","                      StructField('age', IntegerType(), True),\n","                      StructField('profession', StringType(), True),\n","                      StructField('city', StringType(), True),\n","                      StructField('salary', DoubleType(), True)])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["userSchema = StructType().add(\"id\", \"integer\").add(\"name\", \"string\").add(\"age\", \"integer\").add(\"profession\", \"string\").add(\"city\", \"string\").add(\"salary\", \"double\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["StructType([StructField('id', IntegerType(), True), StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('profession', StringType(), True), StructField('city', StringType(), True), StructField('salary', DoubleType(), True)])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["schema1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["StructType([StructField('id', IntegerType(), True), StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('profession', StringType(), True), StructField('city', StringType(), True), StructField('salary', DoubleType(), True)])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["userSchema"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["from pyspark import SparkFiles\n","\n","url = 'https://raw.githubusercontent.com/sadathasan4/spark_streaming/main/d1.csv'\n","\n","spark.sparkContext.addFile(url)\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["\n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://DESKTOP-NBFLQQ9:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[4]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>readfromcsv</code></dd>\n","            </dl>\n","        </div>\n","        "],"text/plain":["<SparkContext master=local[4] appName=readfromcsv>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["spark.sparkContext"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df2 = spark.read.csv(SparkFiles.get(\"d1.csv\"), header=True)\n","df2.head(4)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["[Row(id=1, name='Hasan', age=28, profession='Banker', city='Dhaka', salary=40000.0),\n"," Row(id=2, name='Sayem', age=31, profession='Police Officer', city='Barisal', salary=35000.0),\n"," Row(id=3, name='Raju', age=27, profession='Software Engineer', city='Dhaka', salary=30000.0),\n"," Row(id=4, name='Golam', age=29, profession='Doctor', city='Khulna', salary=50000.0)]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df=spark.read.format(\"csv\").option(\"header\",\"true\").schema(userSchema).load(\"C:/Users/Sad_Mun/Desktop/Data Works/Big Data Course Works/spark_streaming/tmp/txt/d1.csv\")\n","\n","df.head(4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1 = spark.read.csv(\"https://raw.githubusercontent.com/sadathasan4/spark_streaming/main/d1.csv\", header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfCSV = spark.readStream.option(\"sep\", \",\").option(\"header\", \"true\").option(\"maxFilesPerTrigger\",1).schema(userSchema).csv(\"file://C:/Users/Sad_Mun/Desktop/Data Works/Big Data Course Works/spark_streaming/tmp/txt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["customer = spark.readStream.format(\"csv\").schema(schema1)\\\n","            .option(\"header\",True).option(\"maxFilesPerTrigger\",1)\\\n","            .load(\"https://raw.githubusercontent.com/sadathasan4/spark_streaming/main\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM9yUivSsBIDcb92yUwHWAn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
